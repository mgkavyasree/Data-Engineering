{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFNmQpIeq9Nm",
        "outputId": "4425a5c0-66bf-4a89-e692-d1d8f093828f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark and Delta Lake are ready!\n"
          ]
        }
      ],
      "source": [
        "!pip install delta-spark==3.2.0 -q\n",
        "import pyspark\n",
        "from delta import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Create a SparkSession with Delta Lake extensions\n",
        "# The '.config(...)' lines are crucial for enabling Delta Lake's features\n",
        "builder = pyspark.sql.SparkSession.builder.appName(\"DeltaTutorial\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "# Get or create the SparkSession\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "\n",
        "print(\"Spark and Delta Lake are ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {(\"amit\",28),(\"priya\",32),(\"rahul\",25)}\n",
        "df = spark.createDataFrame(data,[\"name\",\"age\"])\n",
        "df.write.format(\"delta\").saveAsTable(\"managed_people\")\n",
        "\n",
        "spark.sql(\"select * from managed_people\").show()\n",
        "\n",
        "location = spark.sql(\"describe detail managed_people\").collect()[0]['location']\n",
        "print(\"managed table location: \",location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70W8_9VjrAzd",
        "outputId": "f100b927-d7b1-4189-d1d6-74e2dc3988f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|priya| 32|\n",
            "|rahul| 25|\n",
            "| amit| 28|\n",
            "+-----+---+\n",
            "\n",
            "managed table location:  file:/content/spark-warehouse/managed_people\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP managed_people table\n",
        "spark.sql(\"drop table managed_people\")\n",
        "# Deletes both table data and metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKmUOVRbtfVk",
        "outputId": "871494e3-1624-4a78-af4f-ef01163305f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Install dependencies\n",
        "!pip install pyspark==3.5.1 delta-spark==3.2.0 -q"
      ],
      "metadata": {
        "id": "dAEwAMxKuMfn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pyspark\n",
        "from delta import configure_spark_with_delta_pip"
      ],
      "metadata": {
        "id": "tGf23HrkuQbj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TNys4IluTLK",
        "outputId": "951e7e39-9610-4f4c-e18d-9cb3d6aa51ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to CSV in Google Drive\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/suppliers.csv\"\n",
        "\n",
        "# Read CSV\n",
        "df = spark.read.option(\"header\", \"true\").csv(csv_path)\n",
        "print(\"Original CSV data:\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPl1GUpyuaZB",
        "outputId": "27220119-b4d3-439b-9b5f-1dfd59a9ba98"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original CSV data:\n",
            "+-----------+------------------+--------------------+---------+\n",
            "|supplier_id|              name|        contact_info| location|\n",
            "+-----------+------------------+--------------------+---------+\n",
            "|          1|       ABC Traders|       abc@gmail.com|   Mumbai|\n",
            "|          2|   Global Supplies| global@supplies.com|    Delhi|\n",
            "|          3|Metro Distributors|metro@distributor...|  Chennai|\n",
            "|          4|          FastMart|contact@fastmart.com|Hyderabad|\n",
            "|          5|       QuickSupply|support@quicksupp...|Bangalore|\n",
            "|          6|         LogiTrade|  info@logitrade.com|     Pune|\n",
            "|          7|          CityMart|  hello@citymart.com|  Kolkata|\n",
            "|          8|     Everest Goods|   reach@everest.com|Ahmedabad|\n",
            "|          9|    NextGen Supply|  nextgen@supply.com|   Jaipur|\n",
            "|         10| Elite Wholesalers| elite@wholesale.com|  Lucknow|\n",
            "+-----------+------------------+--------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as managed Delta table\n",
        "df.write.format(\"delta\").saveAsTable(\"managed_people_from_csv\")\n",
        "print(\"\\nManaged Delta table created.\")\n",
        "\n",
        "# Check location of managed table\n",
        "location = spark.sql(\"DESCRIBE DETAIL managed_people_from_csv\").collect()[0]['location']\n",
        "print(\"Managed table location:\", location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss2Acl9dvKHI",
        "outputId": "dc249ef0-b58b-4fc3-c4f1-793e14c6607b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Managed Delta table created.\n",
            "Managed table location: file:/content/spark-warehouse/managed_people_from_csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop (delete) the table\n",
        "spark.sql(\"DROP TABLE managed_people_from_csv\")\n",
        "print(\"\\nManaged table deleted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2EiAynOvLFu",
        "outputId": "201a9d06-40c4-41c8-f6f1-ede52880bfb6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Managed table deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if original CSV in Google Drive still exists\n",
        "import os\n",
        "if os.path.exists(csv_path):\n",
        "    print(\"CSV in Google Drive still exists.\")\n",
        "else:\n",
        "    print(\"CSV file was deleted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oUzGRHFvUP5",
        "outputId": "d7c0c068-318a-43f1-9782-1413f970a5d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV in Google Drive still exists.\n"
          ]
        }
      ]
    }
  ]
}