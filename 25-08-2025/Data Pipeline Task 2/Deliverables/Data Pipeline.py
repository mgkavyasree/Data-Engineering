# -*- coding: utf-8 -*-
"""sales_data_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12nEJvjhqUMSc0CmsxYy6_mTUlJs2AKIk
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd

# File paths (your Drive must be mounted first)
RAW_FILE = "/content/drive/MyDrive/sales_data.csv"   # Your raw CSV file path
PROCESSED_FILE = "/content/drive/MyDrive/processed_sales_data.csv"

# Step 1: Load the raw data
print("Loading raw sales data...")
df = pd.read_csv(RAW_FILE)
print("Raw Data:")
print(df.head())

# Step 2: Data cleaning
print("\nCleaning data...")
# Remove duplicate rows based on order_id
df = df.drop_duplicates(subset=["order_id"])

# Fill missing region with 'Unknown'
df["region"] = df["region"].fillna("Unknown")

# Fill missing revenue/cost with 0
df["revenue"] = df["revenue"].fillna(0)
df["cost"] = df["cost"].fillna(0)

# Drop rows where order_id is missing (if any)
df = df.dropna(subset=["order_id"])

# Step 3: Enrich data
df["profit"] = df["revenue"] - df["cost"]
# Add profit margin column
df["profit_margin"] = df.apply(
    lambda row: (row["revenue"] - row["cost"]) / row["revenue"] if row["revenue"] != 0 else 0,
    axis=1
)

# Step 4: Categorize customers
def categorize_customer(revenue):
    if revenue > 100000:
        return "Platinum"
    elif revenue > 50000:
        return "Gold"
    else:
        return "Standard"

df["customer_segment"] = df["revenue"].apply(categorize_customer)

# Step 5: Save processed file
df.to_csv(PROCESSED_FILE, index=False)
print(f"\nProcessed data saved to: {PROCESSED_FILE}")

# Step 6: (Optional) Upload to Azure Blob Storage
STORAGE_ACCOUNT_NAME = os.getenv("AZURE_STORAGE_ACCOUNT_NAME")
STORAGE_ACCOUNT_KEY = os.getenv("AZURE_STORAGE_ACCOUNT_KEY")
CONTAINER_NAME = os.getenv("AZURE_CONTAINER_NAME")

if STORAGE_ACCOUNT_NAME and STORAGE_ACCOUNT_KEY and CONTAINER_NAME:
    from azure.storage.blob import BlobServiceClient

    print("Uploading to Azure Blob Storage...")
    blob_service_client = BlobServiceClient(
        account_url=f"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/",
        credential=STORAGE_ACCOUNT_KEY
    )

    blob_client = blob_service_client.get_blob_client(
        container=CONTAINER_NAME, blob="processed_sales_data.csv"
    )

    with open(PROCESSED_FILE, "rb") as data:
        blob_client.upload_blob(data, overwrite=True)

    print("Upload successful!")
else:
    print("Azure credentials not found. Skipping upload.")

from google.colab import files

files.download("/content/drive/MyDrive/processed_sales_data.csv")