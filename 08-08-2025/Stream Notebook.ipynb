{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark"
      ],
      "metadata": {
        "id": "0BjvkET7csID"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Colab PySpark\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "Cm_phHj9cuCR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StringType, IntegerType\n",
        "\n",
        "# Define schema\n",
        "schema = StructType() \\\n",
        "    .add(\"order_id\", StringType()) \\\n",
        "    .add(\"customer_id\", StringType()) \\\n",
        "    .add(\"product\", StringType()) \\\n",
        "    .add(\"quantity\", IntegerType()) \\\n",
        "    .add(\"region\", StringType())\n",
        "\n",
        "# Sample data\n",
        "initial_data = [\n",
        "    (\"1\", \"C101\", \"Laptop\", 2, \"South\"),\n",
        "    (\"2\", \"C102\", \"Chair\", 6, \"North\"),\n",
        "    (\"3\", \"C103\", \"Mobile\", 1, \"East\")\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(initial_data, schema=schema)\n",
        "\n",
        "# Save as CSV in local path\n",
        "output_path = \"/tmp/stream_orders\"  # Local path in Colab VM\n",
        "\n",
        "df.write \\\n",
        "  .mode(\"overwrite\") \\\n",
        "  .option(\"header\", True) \\\n",
        "  .csv(output_path)\n",
        "\n",
        "print(\"Saved to:\", output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejCkcCA6auXA",
        "outputId": "e7860d42-acf8-4bf7-bb0a-2884c02089f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to: /tmp/stream_orders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orders_stream = (\n",
        "    spark.readStream\n",
        "    .schema(schema)\n",
        "    .option(\"header\", True)\n",
        "    .csv(\"/tmp/stream_orders\")  # local path instead of dbfs\n",
        ")"
      ],
      "metadata": {
        "id": "4Ax53oz_asT0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "transformed_orders = orders_stream.withColumn(\n",
        "    \"bulk_order\", when(col(\"quantity\") > 5, True).otherwise(False)\n",
        ")"
      ],
      "metadata": {
        "id": "Ea3uOYFUdHJ7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create rate stream\n",
        "rate_df = (\n",
        "    spark.readStream\n",
        "    .format(\"rate\")\n",
        "    .option(\"rowsPerSecond\", 1)\n",
        "    .load()\n",
        ")\n",
        "\n",
        "# Add is_even column\n",
        "transformed_df = rate_df.withColumn(\"is_even\", (col(\"value\") % 2 == 0))"
      ],
      "metadata": {
        "id": "qPwCLGs-dXC4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Write to memory table\n",
        "query = (\n",
        "    transformed_df.writeStream\n",
        "    .format(\"memory\")         # Write to in-memory table\n",
        "    .queryName(\"rate_table\")  # Query name to use with spark.sql()\n",
        "    .outputMode(\"append\")\n",
        "    .start()\n",
        ")"
      ],
      "metadata": {
        "id": "h_47pWdidgbP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Wait a few seconds for data to accumulate\n",
        "import time\n",
        "time.sleep(5)  # Allow some data to be generated\n"
      ],
      "metadata": {
        "id": "VHbZzJiRdkJJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Query in-memory table\n",
        "spark.sql(\"SELECT * FROM rate_table\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzNGtRlidlTe",
        "outputId": "5efebea2-7f17-460b-8dcf-281f7a277ed2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-------+\n",
            "|           timestamp|value|is_even|\n",
            "+--------------------+-----+-------+\n",
            "|2025-08-08 11:35:...|    0|   true|\n",
            "|2025-08-08 11:35:...|    1|  false|\n",
            "|2025-08-08 11:35:...|    2|   true|\n",
            "|2025-08-08 11:35:...|    3|  false|\n",
            "|2025-08-08 11:35:...|    4|   true|\n",
            "|2025-08-08 11:35:...|    5|  false|\n",
            "|2025-08-08 11:35:...|    6|   true|\n",
            "+--------------------+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Stop the query\n",
        "query.stop()\n"
      ],
      "metadata": {
        "id": "UzFGcJwidmgu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing some variations to this stream\n",
        "\n",
        "# To check the number is a multiple of 5 and 10\n",
        "# Categorize numbers as 'Small', 'Medium', or 'Large'\n",
        "\n",
        "# Transform the stream\n",
        "transformed_df = rate_df \\\n",
        "    .withColumn(\"multiple_of_5\", (col(\"value\") % 5 == 0)) \\\n",
        "    .withColumn(\"multiple_of_10\", (col(\"value\") % 10 == 0)) \\\n",
        "    .withColumn(\"size_category\",\n",
        "                when(col(\"value\") < 10, \"Small\")\n",
        "                .when(col(\"value\") < 50, \"Medium\")\n",
        "                .otherwise(\"Large\"))\n",
        "\n",
        "# Write stream to in-memory table\n",
        "query = (\n",
        "    transformed_df.writeStream\n",
        "    .format(\"memory\")\n",
        "    .queryName(\"rate_table\")  # You can query this later\n",
        "    .outputMode(\"append\")\n",
        "    .start()\n",
        ")\n",
        "\n",
        "# Wait to accumulate data\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "# Query and display the streaming memory table\n",
        "spark.sql(\"SELECT * FROM rate_table\").show()\n",
        "\n",
        "# Stop the stream after viewing\n",
        "query.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1gWbZq4d8LT",
        "outputId": "3334d28b-871f-4399-b876-855eab8ca19b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+-------------+--------------+-------------+\n",
            "|           timestamp|value|multiple_of_5|multiple_of_10|size_category|\n",
            "+--------------------+-----+-------------+--------------+-------------+\n",
            "|2025-08-08 11:43:...|    0|         true|          true|        Small|\n",
            "|2025-08-08 11:43:...|    1|        false|         false|        Small|\n",
            "|2025-08-08 11:43:...|    2|        false|         false|        Small|\n",
            "|2025-08-08 11:43:...|    3|        false|         false|        Small|\n",
            "+--------------------+-----+-------------+--------------+-------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}